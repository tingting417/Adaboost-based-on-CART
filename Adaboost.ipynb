{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weakLearner():\n",
    "    def __init__(self):\n",
    "        self.type_feature = None\n",
    "        self.w = None\n",
    "    def __Gini(self,y,sample_weight):\n",
    "        '''\n",
    "        :param data: \n",
    "        :param sample_weight: 特征数据的权重，NaN表示元数据为空值\n",
    "        :param y: 目标数据\n",
    "        :return: Gini: 返回该特征的Gini系数\n",
    "        '''\n",
    "        ##  根据第一个公式\n",
    "        K = np.unique(y)\n",
    "\n",
    "        gini = 1 - np.sum([(np.sum(sample_weight[y == k])/  np.sum(sample_weight)) **2 for k in K])\n",
    "        \n",
    "        return gini\n",
    "    \n",
    "    def __typeFeature(self,X):\n",
    "        # 表示特征是否为连续还是离散\n",
    "        n_sample,n_feature = X.shape\n",
    "        self.type_feature = []\n",
    "        ####   特征属性小于10个，认为是离散型数据用0表示，连续性数据用1 表示\n",
    "        for f_idx in range(n_feature):\n",
    "            if len(np.unique(X[:, f_idx]))< 10:\n",
    "                self.type_feature.append(0)\n",
    "            else:\n",
    "                self.type_feature.append(1)\n",
    "        return self.type_feature       \n",
    "\n",
    "    def __binSplitData(self,X,y,f_idx,f_val):\n",
    "        '''\n",
    "        二分类划分数据集\n",
    "        :param X 划分数据\n",
    "        :param f_idx: 数据X的第f_idx个特征  X.iloc[:,f_idx]  太慢 用 X.columns[f_idx]\n",
    "          np.unique(X.at[:,f_idx])可以得到该特征的属性，如 array(['Overcast', 'Rain', 'Sunny'], dtype=object)\n",
    "        :param f_val: 数据f_idx个特征中的属性值，即上面中的一种 'Overcast'/ 'Rain'/ 'Sunny\n",
    "        :param type_feature: 离散特征 0 连续特征 1\n",
    "        :return: 二分后的左右数据子集\n",
    "        '''\n",
    "        ### att 数有数据在第f_idx的特征的所有属性,将不等于 f_val 分为一类，其余分为另一类\n",
    "        ####################    0: 离散类型特征二分方法 1:连续数据   ############################\n",
    "        att=X[:, f_idx]\n",
    "        \n",
    "        if self.type_feature[f_idx]== 0:\n",
    "            X_left = X[att == f_val]\n",
    "            X_right = X[att != f_val]\n",
    "            y_left = y[att == f_val]\n",
    "            y_right = y[att != f_val]\n",
    "            weight_left = self.w[att == f_val]\n",
    "            weight_right = self.w[att != f_val]\n",
    "        else:\n",
    "            X_left = X[att <= f_val]\n",
    "            X_right = X[att >f_val]\n",
    "            y_left = y[att <= f_val]\n",
    "            y_right = y[att > f_val]\n",
    "            weight_left = self.w[att <= f_val]\n",
    "            weight_right = self.w[att > f_val]\n",
    "           ## 切分点和样本点的索引\n",
    "        return X_left, X_right, y_left, y_right, weight_left, weight_right\n",
    "    \n",
    "    \n",
    "    def __bestSplit(self,X,y):\n",
    "        '''\n",
    "           \n",
    "        找到最佳分割特征与特征值\n",
    "        :param X\n",
    "        :return: best_f_idx  最佳分割特征 ， best_f_val 特征值\n",
    "         \n",
    "        '''\n",
    "        ini_gain = 1\n",
    "        n_sample,n_feature = X.shape\n",
    "        ## 第一个终止条件： 当叶子节点中的样本数小于最小分割值，或者所有样本属于同一类别时，不再分割\n",
    "        \n",
    "        ##-------------------------通过不断二分的过程 寻找对于某个特征，的最佳分割点---------------------------\n",
    "        for f_idx in range(n_feature):\n",
    "        ##-------------------------如果该特征中的属性个数小于10，则认为是离散数据 type_feature = 0，否则else---------------------------\n",
    "\n",
    "            if self.type_feature[f_idx] == 0:\n",
    "                for f_val in np.unique(X[:, f_idx]):\n",
    "                    ## 当某个特征只有两个类别时，仅仅做一次左右子树的划分，不用重复操作\n",
    "                    if len(np.unique(X[:, f_idx]))== 2 and f_val == np.unique(X[:, f_idx])[0]:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        X_left, X_right, y_left, y_right, weight_left, weight_right = self.__binSplitData(X,y,f_idx,f_val)\n",
    "\n",
    "                        Gini_after = np.sum(weight_left) * self.__Gini(y_left,weight_left) + np.sum(weight_right) * self.__Gini(y_right,weight_right)\n",
    "                        if Gini_after > ini_gain: \n",
    "                            continue\n",
    "                        else:\n",
    "                            ini_gain = Gini_after\n",
    "                            best_f_idx,best_f_val = f_idx,f_val\n",
    "        ##-------------------------     连续特征属性的二分 case = 1   ---------------------------\n",
    "            else:\n",
    "                for f_val in np.linspace(np.nanmin(X[:, f_idx])+1,np.nanmax(X[:, f_idx])-1,num=50):\n",
    "                        X_left, X_right, y_left, y_right, weight_left, weight_right = self.__binSplitData(X,y,f_idx,f_val)\n",
    "                        Gini_after = np.sum(weight_left) * self.__Gini(y_left,weight_left) + np.sum(weight_right) * self.__Gini(y_right,weight_right)\n",
    "                    \n",
    "                        if Gini_after > ini_gain: \n",
    "                            continue\n",
    "                        else:\n",
    "                            ini_gain = Gini_after\n",
    "                            best_f_idx,best_f_val = f_idx,f_val\n",
    "                        \n",
    "\n",
    "        return best_f_idx,best_f_val\n",
    "    \n",
    "    def __CART(self,X,y):\n",
    "        '''\n",
    "        生成CART树\n",
    "        :param X： 特征数据\n",
    "        :param y: 目标数据\n",
    "        :return; CART 树\n",
    "        '''\n",
    "        best_f_idx, best_f_val = self.__bestSplit(X,y)\n",
    "        tree = dict()\n",
    "        tree['cut_f'] = best_f_idx\n",
    "        tree['cut_val'] = best_f_val\n",
    "        X_left, X_right, y_left, y_right, weight_left, weight_right = self.__binSplitData(X,y,best_f_idx,best_f_val)\n",
    "        tree['left_tree'] = y_left\n",
    "        tree['right_tree'] = y_right\n",
    "        tree['left_weight'] = weight_left\n",
    "        tree['right_weight'] = weight_right\n",
    "        return tree  \n",
    "    \n",
    "    \n",
    "    def train(self,X,y,sample_weight):\n",
    "        self.w = sample_weight\n",
    "        self.type_feature = self.__typeFeature(X) \n",
    "        self.tree = self.__CART(X,y)\n",
    "        return self.tree\n",
    "        \n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        return np.array([self.__predict_one(x_test, self.tree) for x_test in X_test])\n",
    "    \n",
    "    def __predict_one(self,x_test,tree):\n",
    "            cut_f_idx, cut_val = tree['cut_f'], tree['cut_val']\n",
    "            label_left = Counter(tree['left_tree']).most_common(1)[0][0]\n",
    "            label_right = Counter(tree['right_tree']).most_common(1)[0][0]\n",
    "            if self.type_feature[cut_f_idx] == 0:\n",
    "                result = label_left if x_test[cut_f_idx] == cut_val else label_right\n",
    "            else:\n",
    "                result = label_left if x_test[cut_f_idx] <= cut_val else label_right\n",
    "            return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost():\n",
    "    def __init__(self,estimators: int = 10, classifier = weakLearner):\n",
    "        self.estimators = estimators\n",
    "        self.w = None \n",
    "        self.alphas = []\n",
    "        self.stumps = []\n",
    "        self.weakLearner = classifier\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.w = np.array([1 / len(X)] * len(X))\n",
    "        M = self.estimators\n",
    "        for m in range(M):\n",
    "            G_m = self.weakLearner()\n",
    "            tree = G_m.train(X,y,self.w)\n",
    "            ###'cut_f'   'cut_val'  'left_tree'   'right_tree',  'left_weight'   'right_weight',\n",
    "            label_left = np.array([Counter(tree['left_tree']).most_common(1)[0][0]] * len(tree['left_tree']) ) \n",
    "            label_right = np.array([Counter(tree['right_tree']).most_common(1)[0][0]] * len(tree['right_tree'])) \n",
    "            \n",
    "            error = 1e-6 + np.sum(tree['left_weight'] * (tree['left_tree'] != label_left)) + np.sum(tree['right_weight'] * (tree['right_tree'] != label_right))\n",
    "            alpha = 1/2 * np.log((1-error)/error) \n",
    "            y_temp = np.hstack((tree['left_tree'],tree['right_tree']))\n",
    "            G = np.hstack((label_left,label_right))                     \n",
    "            Zm = np.sum(self.w * np.exp(- y_temp * G  * alpha))\n",
    "            #Zm = 2 * np.sqrt(error * (1-error))\n",
    "            self.w = self.w * np.exp(- y_temp * G  * alpha)\n",
    "            self.stumps.append(G_m)\n",
    "            self.alphas.append(alpha)\n",
    "    def predict(self,X_test):\n",
    "                                    \n",
    "        M = self.estimators\n",
    "        y_ = 0\n",
    "        for m in range(M):\n",
    "            y_ += self.alphas[m] * self.stumps[m].predict(X_test)\n",
    "        return np.sign(y_)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from collections import  Counter\n",
    "    from sklearn import datasets\n",
    "    import  numpy as np    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    iris = datasets.load_iris()\n",
    "    iris.target[iris.target > 0] = 1\n",
    "    iris.target[iris.target == 0] = -1\n",
    "    X, Y = iris.data, iris.target\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    tree_clf = Adaboost()\n",
    "    tree = tree_clf.fit(X_train,Y_train)\n",
    "    Y_pred = tree_clf.predict(X_test)\n",
    "    print('acc:{}'.format(np.sum(Y_pred == Y_test) / len(Y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
